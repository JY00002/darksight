<!DOCTYPE html>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>DarkSight - Interpreting Deep Classifier by Visual Distillation of Dark Knowledge</title>

  <!-- CSS  -->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <link href="css/materialize.css" type="text/css" rel="stylesheet" media="screen,projection"/>
  <link href="css/style.css" type="text/css" rel="stylesheet" media="screen,projection"/>
</head>
<script type="text/javascript" src="https://cdn.staticfile.org/jquery/3.2.1/jquery.js"></script>
<script src="js/materialize.js"></script>
<script src="js/init.js"></script>
<body>
  <nav class="white" role="navigation">
    <div class="nav-wrapper container">
      <a id="logo-container" href="#" class="brand-logo">DarkSight</a>
      <ul class="right hide-on-med-and-down">
        <li><a href="https://arxiv.org/abs/1803.04042">arXiv</a></li>
        <li><a href="https://github.com/xukai92/darksight">Source Code</a></li>
        <li><a href="./demo/mnist.html">Demo</a></li>
      </ul>

      <ul id="nav-mobile" class="side-nav">
        <li><a href="https://arxiv.org/abs/1803.04042">arXiv</a></li>
        <li><a href="https://github.com/xukai92/darksight">Source Code</a></li>
        <li><a href="./demo/mnist.html">Demo</a></li>
      </ul>
      <a href="#" data-activates="nav-mobile" class="button-collapse"><i class="material-icons">menu</i></a>
    </div>
  </nav>

  <div id="index-banner" class="parallax-container">
    <div class="section no-pad-bot">
      <div class="container">
        <br><br>
        <h1 class="header center teal-text text-lighten-2">DarkSight</h1>
        <div class="row center">
          <h5 class="header col s12 light">Interpreting Deep Classifier by Visual Distillation of Dark Knowledge</h5>
          <h5><small><a class="white-text" href="http://xuk.ai/">Kai Xu</a>, <a class="white-text" href="https://sites.google.com/site/daehpark/">Dae Hoon Park</a>, <a class="white-text" href="http://www.yichang-cs.com/">Chang Yi</a> and <a class="white-text" href="http://homepages.inf.ed.ac.uk/csutton/">Charles Sutton</a></small></h5>
        </div>
        <!-- <div class="row center">
          <a href="http://materializecss.com/getting-started.html" id="download-button" class="btn-large waves-effect waves-light teal lighten-1">Get Started</a>
        </div> -->
        <!-- <br><br> -->
      </div>
    </div>
    <div class="parallax"><img src="dark-knowledge-1.jpg" alt="Dark knowledge img 1"></div>
  </div>


  <div class="container">
    <div class="section">

        <div class="row">
        <div class="col s12 center">
            <h3><i class="mdi-content-send brown-text"></i></h3>
            <h4>Abstract</h4>
            <p class="left-align light">
            Interpreting black box classifiers, such as deep
            networks, allows an analyst to validate a classifier
            before it is deployed in a high-stakes setting. A
            natural idea is to visualize the deep network’s representations, so as to “see what the network sees”.
            In this paper, we demonstrate that standard dimension
            reduction methods in this setting can yield
            uninformative or even misleading visualizations.
            Instead, we present DarkSight, which visually
            summarizes the predictions of a classifier in a way
            inspired by notion of dark knowledge. DarkSight
            embeds the data points into a low-dimensional
            space such that it is easy to compress the deep
            classifier into a simpler one, essentially combining
            model compression and dimension reduction.
            We compare DarkSight against t-SNE both qualitatively
            and quantitatively, demonstrating that
            DarkSight visualizations are more informative.
            Our method additionally yields a new confidence
            measure based on dark knowledge by quantifying
            how unusual a given vector of predictions is.
            </p>
        </div>
        </div>

    </div>
    </div>
    


  <div class="parallax-container valign-wrapper">
    <div class="section no-pad-bot">
      <div class="container">
        <div class="row center">
          <h5 class="header col s12 light">See what the network sees by performing dimension reduction and model compression jointly.</h5>
        </div>
      </div>
    </div>
    <div class="parallax"><img src="dark-knowledge-2.jpg" alt="Dark knowledge img 2"></div>
  </div>
  <div class="container">
    <div class="section">

        <!--   Icon Section   -->
        <div class="row">

          <div class="col s12 m4">
            <div class="icon-block">
            <h2 class="center brown-text"><i class="material-icons">visibility</i></h2>
            <h5 class="center">Looking into LeNet on MNIST</h5>

            <p class="light">
                <img class="materialboxed" data-caption="2D Scatter Plot for LeNet on MNIST" width="100%" src="./lenet-mnist.png">
            </p>
            </div>
          </div>

          <div class="col s12 m4">
            <div class="icon-block">
            <h2 class="center brown-text"><i class="material-icons">priority_high</i></h2>
            <h5 class="center">Outlier Detection</h5>

            <p class="light">
              Outlier detection can be done by simply picking instances on the corner of the scatter plot or using a confidence measure based on density of DarkSight embedding.
              Some outliers detected are:
            </p>
            <p>
              <img data-caption="A picture of a way with a group of trees in a park" width="18%" src="./demo/images/mnist/test/3316.jpg">
              <img data-caption="A picture of a way with a group of trees in a park" width="18%" src="./demo/images/mnist/test/6576.jpg">
              <img data-caption="A picture of a way with a group of trees in a park" width="18%" src="./demo/images/mnist/test/3941.jpg">
              <img data-caption="A picture of a way with a group of trees in a park" width="18%" src="./demo/images/mnist/test/9779.jpg">
              <img data-caption="A picture of a way with a group of trees in a park" width="18%" src="./demo/images/mnist/test/3005.jpg">
              <img data-caption="A picture of a way with a group of trees in a park" width="18%" src="./demo/images/mnist/test/6574.jpg">
              <img data-caption="A picture of a way with a group of trees in a park" width="18%" src="./demo/images/mnist/test/2293.jpg">
              <img data-caption="A picture of a way with a group of trees in a park" width="18%" src="./demo/images/mnist/test/7999.jpg">
              <img data-caption="A picture of a way with a group of trees in a park" width="18%" src="./demo/images/mnist/test/3599.jpg">
              <img data-caption="A picture of a way with a group of trees in a park" width="18%" src="./demo/images/mnist/test/8326.jpg">
            </p>
            </div>
          </div>

          <div class="col s12 m4">
            <div class="icon-block">
                <h2 class="center brown-text"><i class="material-icons">flash_on</i></h2>
                <h5 class="center">Fast Training</h5>

                <p class="light">
                  DarkSight is trained in O(N) and is GPU friendly. 
                  With the PyTorch implementation we provided in <a href="https://github.com/xukai92/darksight">GitHub</a>, 
                  DarkSight plot for a 10-class classifier on 10,000 instances can be generated within around 1.5 minutes with a single GPU.
                </p>
            </div>
          </div>
        </div>

        <div class="row">
          <div class="col s12 m12">
            <h2 class="center brown-text">
              <i class="medium material-icons">question_answer</i>
            </h2>
            <h5 class="center">Why not using t-SNE?</h5>
            
            <p class="light">
              Most closely related work to ours is the proposal by <a href="https://cs.stanford.edu/people/karpathy/cnnembed/">Andrej Karpathy</a> to apply t-SNE to the features from the second
              to last layer in a deep classifier, producing a two-dimensional embedding in which nearby data items have similar high-level
              features according to the network. However, we observe that these plots can
              be misleading because they contain well-separated clusters even when, in fact, there are many points nearby the decision
              boundary.
            </p>
          </div>
        </div>

      </div>
    </div>


  <!-- <div class="parallax-container valign-wrapper">
    <div class="section no-pad-bot">
      <div class="container">
        <div class="row center">
          <h5 class="header col s12 light">A modern responsive front-end framework based on Material Design</h5>
        </div>
      </div>
    </div>
    <div class="parallax"><img src="background3.jpg" alt="Unsplashed background img 3"></div>
  </div> -->

  <footer class="page-footer teal">
    <div class="container">
      <div class="row">
        <div class="col l7 s12">
          <h5 class="white-text">Acknowledgement</h5>
          <p class="grey-text text-lighten-4">
            This work was funded by Edinburgh Huawei Research Lab, which is generously funded by Huawei Technologies Co. Ltd. 
            We thank Rich Caruana for his useful comments and suggestions on how to use DarkSight. We also thank Cole Hurwitz
            for his careful grammar checking of the paper, and Yiran Tao for his work on the demo of DarkSight.
          </p>
        </div>

        <div class="col l2 s12">
          <h5 class="white-text">Authors</h5>
          <ul>
            <li><a class="white-text" href="http://xuk.ai/">Kai Xu</a></li>
            <li><a class="white-text" href="https://sites.google.com/site/daehpark/">Dae Hoon Park</a></li>
            <li><a class="white-text" href="http://www.yichang-cs.com/">Chang Yi</a></li>
            <li><a class="white-text" href="http://homepages.inf.ed.ac.uk/csutton/">Charles Sutton</a></li>
          </ul>
        </div>

        <div class="col l3 s12">
          <h5 class="white-text">Connect</h5>
          <ul>
            <li>
              <a class="white-text" href="http://www.anc.ed.ac.uk/">Institute for Adaptive and Neural Computation, University of Edinburgh</a>
            </li>
            <li>
              <a class="white-text" href="http://web.inf.ed.ac.uk/infweb/partners/edinburgh-huawei-research-lab">Edinburgh Huawei Research Lab</a>
            </li>
            <li>
              <a class="white-text" href="http://groups.inf.ed.ac.uk/cup/">Charles's Uncertain People</a>
            </li>    
          </ul>
        </div>
      </div>
    </div>
    <div class="footer-copyright">
      <div class="container">
      Made by <a class="brown-text text-lighten-3" href="http://materializecss.com">Materialize</a>
      </div>
    </div>
  </footer>

  </body>
</html>
